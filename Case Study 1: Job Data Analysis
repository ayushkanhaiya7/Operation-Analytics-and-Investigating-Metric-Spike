/* Job Data Analysis   */

create database operation_analytics;

use operation_analytics;

/*Case Study 1 - Job Data Analysis */

create table job_data(
job_id int,
actors_id int,
event varchar(255),
language varchar(255),
time_spent int,
org varchar(255),
ds date);

select * from job_data;

INSERT INTO job_data (job_id, actor_id, event, language, time_spent, org, ds)
VALUES               ( 88, 102, 'decision', 'English',    12,  'D' '2020-11-30'),
                     ( 45, 106, 'transfer', 'Portuguese', 26,  'B' '2020-11-30'),
                     ( 56, 103, 'skip',     'Sanskrit',   78,  'C' '2020-11-30'),
                     ( 89, 105, 'transfer', 'Sanskrit',   67,  'A' '2020-11-30'),
                     ( 25, 102, 'decision', 'Hindi',      56,  'B' '2020-11-30'),
                     ( 34, 107, 'skip',     'French',     23,  'A' '2020-11-30'),
                     ( 56, 104, 'skip',     'Sanskrit',   456, 'D' '2020-11-30'),
                     ( 14, 104, 'decision', 'Italian',    15,  'C' '2020-11-30');


/* Jobs reviewed per hour per day for November 2020*/

select 
count(distinct job_id)/(30*24) as num_jobs_reviewed
from job_data
where 
ds between '2020-11-01' and '2020-11-30';

/* 7-day rolling average of throughput */

select ds, 
       jobs_reviewed,
       avg(jobs_reviewed)over(order by ds rows between 6 preceding and current row) as throughput_7
from
(
select ds, count(distinct job_id) as jobs_reviewed
from job_data
where ds between '2020-11-01' and '2020-11-30'
group by ds
)a;

/* Percentage share of each language in the last 30 days*/

select language,
num_jobs,
100.0* num_jobs/total_jobs as pct_share_lang
from
(
select language, count(distinct job_id) as num_jobs
from job_data
group by language
)a
cross join
(
select count(distinct job_id) as total_jobs 
from job_data
)b;

/* Duplicate Rows Detection */

select * from
(
select *,
row_number()over(partition by job_id) as rownum 
from job_data
)a 
where rownum>1;
